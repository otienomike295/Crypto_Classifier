{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5589808e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… README.md successfully created at: c:\\Users\\atien\\Downloads\\Data Science Class\\Capstone_Project\\Crypto_Classifier\\README.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# FULL README CONTENT\n",
    "# ==========================================\n",
    "readme_text = \"\"\"\n",
    "# ðŸ“˜ Crypto Buy/Sell Classification Capstone\n",
    "### End-to-End Machine Learning Pipeline Using Real Binance Data\n",
    "\n",
    "**Status:** Completed\n",
    "**UI:** Streamlit Dashboard Included\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Project Overview\n",
    "\n",
    "This project implements a fully automated Machine Learning pipeline that predicts cryptocurrency market movements (Buy, Sell, or Hold). It fetches historical data from the **Binance API**, processes technical indicators, trains multiple ML models (XGBoost, Random Forest, CatBoost, etc.), and evaluates them to select the best performer.\n",
    "\n",
    "### Key Features\n",
    "*   **Real-time Data:** Fetches live/historical OHLCV data directly from Binance.\n",
    "*   **Feature Engineering:** Calculates RSI, MACD, Bollinger Bands, and Moving Averages.\n",
    "*   **Dynamic Labeling:** Solves class imbalance using volatility-based thresholds.\n",
    "*   **Model Arena:** Trains 5 different algorithms and automatically promotes the winner.\n",
    "*   **Interactive UI:** A web-based dashboard to visualize charts and AI signals.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Project Structure\n",
    "\n",
    "```text\n",
    "crypto-classifier/\n",
    "â”‚â”€â”€ data/\n",
    "â”‚   â”œâ”€â”€ raw/                  # raw_data.csv\n",
    "â”‚   â”œâ”€â”€ processed/            # processed_data.csv\n",
    "â”‚   â”œâ”€â”€ feature_engineered/   # feature_engineered_data.csv\n",
    "â”‚   â”œâ”€â”€ labeled/              # labeled_data.csv\n",
    "â”‚\n",
    "â”‚â”€â”€ notebooks/\n",
    "â”‚   â”œâ”€â”€ 01_fetch_data.ipynb\n",
    "â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb\n",
    "â”‚   â”œâ”€â”€ 03_model_training.ipynb\n",
    "â”‚   â”œâ”€â”€ 04_evaluation.ipynb\n",
    "â”‚   â”œâ”€â”€ 05_binance_prediction.ipynb\n",
    "â”‚\n",
    "â”‚â”€â”€ src/\n",
    "â”‚   â”œâ”€â”€ data_fetcher.py       # Fetches from Binance\n",
    "â”‚   â”œâ”€â”€ data_processor.py     # Cleans data types\n",
    "â”‚   â”œâ”€â”€ feature_generator.py  # Calculates Indicators (RSI, MACD)\n",
    "â”‚   â”œâ”€â”€ labeler.py            # Generates Targets (Buy/Sell)\n",
    "â”‚   â”œâ”€â”€ train.py              # Trains all models\n",
    "â”‚   â”œâ”€â”€ evaluate.py           # Evaluates and picks winner\n",
    "â”‚   â”œâ”€â”€ predict.py            # Prediction Logic\n",
    "â”‚   â”œâ”€â”€ app.py                # Streamlit UI\n",
    "â”‚\n",
    "â”‚â”€â”€ models/                   # Saved .pkl models\n",
    "â”‚â”€â”€ README.md\n",
    "â”‚â”€â”€ requirements.txt\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "3. How to Run the Pipeline\n",
    "You can run the entire workflow from the terminal using these commands in order:\n",
    "Phase 1: Data Engineering\n",
    "code\n",
    "Bash\n",
    "# 1. Fetch raw data\n",
    "python src/data_fetcher.py\n",
    "\n",
    "# 2. Clean data types\n",
    "python src/data_processor.py\n",
    "\n",
    "# 3. Generate Technical Indicators\n",
    "python src/feature_generator.py\n",
    "\n",
    "# 4. Generate Targets (Dynamic Imbalance Fix)\n",
    "python src/labeler.py\n",
    "Phase 2: Machine Learning\n",
    "code\n",
    "Bash\n",
    "# 5. Train Model Zoo (XGBoost, CatBoost, RF, etc.)\n",
    "python src/train.py\n",
    "\n",
    "# 6. Evaluate & Select Best Model\n",
    "python src/evaluate.py\n",
    "Phase 3: User Interface\n",
    "To launch the interactive dashboard:\n",
    "code\n",
    "Bash\n",
    "streamlit run src/app.py\n",
    "4. Notebooks Guide\n",
    "01_fetch_data.ipynb: ETL process visualization.\n",
    "02_feature_engineering.ipynb: Visualization of RSI, MACD, and Price.\n",
    "03_model_training.ipynb: Training logs and validation scores.\n",
    "04_evaluation.ipynb: Confusion matrix and performance report of the winner.\n",
    "05_binance_prediction.ipynb: Testing the model on specific scenarios.\n",
    "\"\"\"\n",
    "#==========================================\n",
    "#WRITE FILE TO DISK\n",
    "#==========================================\n",
    "#Determine path (handles running from notebooks folder or root)\n",
    "if os.path.exists(\"../src\"):\n",
    "# Running inside 'notebooks/' folder, go up one level\n",
    "    readme_path = \"../README.md\"\n",
    "else:\n",
    "#    Running inside root folder\n",
    "    readme_path = \"README.md\"\n",
    "#Write the file\n",
    "with open(readme_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(readme_text)\n",
    "print(f\"âœ… README.md successfully created at: {os.path.abspath(readme_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1424a6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… .gitignore file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "gitignore_content = \"\"\"\n",
    "# Ignore Virtual Environment\n",
    "myVENV/\n",
    "venv/\n",
    "env/\n",
    "__pycache__/\n",
    "*.pyc\n",
    "\n",
    "# Ignore Dataset (Too large for GitHub)\n",
    "data/raw/*.csv\n",
    "data/processed/*.csv\n",
    "data/feature_engineered/*.csv\n",
    "data/labeled/*.csv\n",
    "\n",
    "# Ignore System Files\n",
    ".DS_Store\n",
    ".ipynb_checkpoints/\n",
    "\"\"\"\n",
    "\n",
    "# Write the file to the root folder\n",
    "with open(\"gitignore.txt\", \"w\") as f:\n",
    "    f.write(gitignore_content)\n",
    "\n",
    "# Rename it to .gitignore (Windows sometimes hides dotfiles, so we do it via python)\n",
    "if os.path.exists(\".gitignore\"):\n",
    "    os.remove(\".gitignore\")\n",
    "os.rename(\"gitignore.txt\", \".gitignore\")\n",
    "\n",
    "print(\"âœ… .gitignore file created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myVENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
